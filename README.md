# 知乎话题关系图

## 关于此项目

早期想要学习数据分析，就拿知乎练手，期间碰到很多问题，也发现很多有趣的事情。然后，由于课多考试多，这个东西不知不觉放了半年，此项目的细节已经忘记了一大半，期间的资料也基本丢失了，只剩余这几行代码，供有缘人查看。

## 内容
- `crawl_data.py`： 爬取知乎话题，保存到MySQL。（为了成功保存到MySQL，需要按照config中的信息配置`zhihu`数据库并添加`t_topic`表，代码中的去重语句要求表中第一个字段名必须是`t_topic_id`，样例表见下方表格）
- `config.py` ： 上面程序对应的配置文件
- `cookies.txt`： 好像没用。
- `topic.py`： 一个没多大用的话题类。
- `login_zhihu/gain_login_cookies.py`： 顾明司仪，用来生成cookies值，带验证码识别的程序丢失了，这是个早期版本。
- `login_zhihu/login_config.py`： 上面程序的配置文件。
- `environment`： 貌似跟这个代码没什么关系啊。
- `其他`： 用Pycharm打开产生的垃圾文件，懒得删。

**Example: MySQL.zhihu.t_topic**

| t_topic_id | t_topic_name  |  t_topic_followers  |   t_topic_description   |  t_topic_parent   |  t_topic_son   |
| --------    | ----------     | ------------------ |  ------------------------ | ------------| ---------------- |
| 19776749        | 「根话题」      |   154211    | 知乎的全部话题通过父子关系构成一个有根无循环的有向图。「根话题」即为所有话题的最上层的父话题。话题精华即为知乎的 Top1000 高票回答。请不要在问题上直接绑定「根话题」。这样会使问题话题过于宽泛。 | -1 | 19776751,19618774,19778287,19778298,19560891,19778317 |

## 进展

没有进展。

## 后续

也没有后续。

当然，如果你愿意的话，可以为代码加入代理池，但是我觉得对于知乎，使用代理池没什么用，因为他的反爬策略很特殊的，当用户访问资源过于频繁，封的是账户不是IP，你可以试试，至少我当时是手机和电脑访问知乎都受限制了。

对此，我想到的办法是使用多账户多线程爬取话题信息。而且递归非常影响爬取的速度，当时并没有什么好方法。

## 求助

如果你是此项目的有缘人，欢迎和我交流。如果想知道其中详细的爬取过程，请邮箱联系我！！
